{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "from enum import Enum\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import typing as t\n",
    "\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    show_photos, \n",
    "    create_dataloader,\n",
    "    train_epoch,\n",
    "    test_epoch,\n",
    "    plot_history,\n",
    "    print_model_params_required_grad,\n",
    "    PUBLIC_DATA_FOLDER_PATH,\n",
    "    PUBLIC_DATA_DESCRIPTION_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Yandex GO is one of the top three ride-hailing services in the world. Our app facilitates over 4 billion trips per year across 32 countries. We are committed to the quality of our services, ensuring thorough checks of both drivers and their vehicles before they go online, based on dozens of criteria. Part of the vehicle inspection process is carried out remotely using photos of the vehicle, which allows us to either block or grant the driver access to orders. This tool ensures that cars do not go online if they are damaged or dirty.\n",
    "\n",
    "Computer vision algorithms play a significant role in this remote quality control process. Machine learning models act as a filter that processes vehicle inspection requests, automatically approving a portion of requests that, according to the models, contain no violations, and sending suspicious cases for additional manual review.\n",
    "\n",
    "### How does the photo inspection process work?\n",
    "As part of vehicle photo inspections, drivers periodically receive a task to take photos of their car, so it can be checked for damage, compliance with service standards, branding presence, etc. Before these checks, we also need to ensure that drivers took the photos honestly and sent what we expected. The driver is required to take 4 photos (front, rear, left side, right side). The photos are taken through the Yandex PRO app, which has an interface that guides them to capture the 4 photos in the correct order and from the required angles.\n",
    "\n",
    "In the standard process, the photos are first reviewed by ML pipeline. If ML pipeline doesn't find anything suspicious in the photos, the inspection is automatically approved. If the pipeline flags at least one photo, the inspection is sent to an assessor for a final decision. Thus, the object for decision-making is the inspection itself, i.e., all 4 photos together.\n",
    "\n",
    "In this task, the license plate numbers have been blacked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_id = '000f43a6549ad26d'\n",
    "photos = []\n",
    "for side in ['front', 'back', 'left', 'right']:\n",
    "    with open(f'{PUBLIC_DATA_FOLDER_PATH}/{pass_id}_{side}', 'rb') as file:\n",
    "        photos.append(file.read())\n",
    "show_photos(photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description: \n",
    "- **filename** —  name of the photo file, consisting of `pass_id` and `plan_side`.\n",
    "- **pass_id** — ID of the inspection. Each inspection contains 4 photos.\n",
    "- **plan_side** — the side of the vehicle that should be in the photo. Possible values: front, back, left, right.\n",
    "- **fact_side** — the side of the vehicle as determined by assessors. Possible values: front, back, left, right, unknown.\n",
    "- **fraud_verdict** — the assessor's verdict on what is depicted in the photo. Possible values:\n",
    "   - ALL_GOOD —  the photo clearly shows one side of the vehicle, which is fully visible and in focus.\n",
    "   - LACK_OF_PHOTOS — the photo does not contain a vehicle at all.\n",
    "   - BLURRY_PHOTO — the photo is blurry.\n",
    "   - SCREEN_PHOTO — not a real vehicle photo, but a photo of a screen.\n",
    "   - DARK_PHOTO — the photo is too dark.\n",
    "   - INCOMPLETE_CAPTURE — the vehicle is not fully visible in the photo.\n",
    "- **fraud_probability** — the proportion of assessors who assigned the given fraud_verdict. If no verdict achieved a majority, a random one is chosen.\n",
    "- **damage_verdict** — the assessor's verdict on the vehicle's condition. Possible values:\n",
    "   - NO_DEFECT —  no visible damage.\n",
    "   - DEFECT — the is some damage.\n",
    "   - BAD_PHOTO — can't say anything about the damage, because of photo's quality.\n",
    "- **damage_probability** — the proportion of assessors who assigned the given damage_verdict. If no verdict achieved a majority, a random one is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = pd.read_csv(PUBLIC_DATA_DESCRIPTION_PATH, index_col='filename').sort_index()\n",
    "description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to fraud that can be identified by looking at an individual photo, there may be cases where each photo individually has a fraud_verdict of 'ALL_GOOD', but the driver took two photos of the same side of the vehicle and failed to capture another side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description[description.pass_id == '001c07aa1e3edf7e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "To assess the quality of vehicles and photos using machine learning algorithms:  \n",
    "1. For detecting fraud (incorrect photos, unclear images, or incorrect photo sets).  \n",
    "2. For detecting vehicle damage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metric and Deliverables\n",
    "There are 2 targets and 4 sides of a vehicle in each exam. But after all, we need to predict whether the inspection should be sent to a human for review to provide feedback to the driver, or if there are no defects and the inspection can be automatically approved. This means that the metric is calculated not for individual photos for each target, but for the inspection as a whole.\n",
    "\n",
    "*Evaluation Metric:* ROC AUC (object — inspection)\n",
    "\n",
    "*Required Deliverables*:\n",
    "- Model Weights: The trained model's weights for reproducibility and further analysis.\n",
    "- Executable Script: A script containing all necessary code to run the model, including data reading, preprocessing steps, model architecture, inference code.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train a fraud detection model with a simplified target that does not account for cases where two photos in an inspection may capture the same side of the vehicle. For this, we will use a pretrained ResNet18 model and replace its classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarSide(Enum):\n",
    "    FRONT = 0\n",
    "    BACK = 1\n",
    "    LEFT = 2\n",
    "    RIGHT = 3\n",
    "    UNKNOWN = 5\n",
    "    \n",
    "class FraudResolution(Enum):\n",
    "    ALL_GOOD = 0\n",
    "    LACK_OF_PHOTOS = 1\n",
    "    BLURRY_PHOTO = 2\n",
    "    SCREEN_PHOTO = 3\n",
    "    DARK_PHOTO = 4\n",
    "    INCOMPLETE_CAPTURE = 5\n",
    "    RUDE_CONTENT = 6\n",
    "    \n",
    "class DamageResolution(Enum):\n",
    "    NO_DEFECT = 0\n",
    "    DEFECT = 1\n",
    "    BAD_PHOTO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_STD = [0.229, 0.224, 0.225]\n",
    "RESIZE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "def pil_open(image_data: bytes) -> Image:\n",
    "    return Image.open(io.BytesIO(image_data))\n",
    "\n",
    "\n",
    "def preprocess(image_data: t.Optional[bytes]) -> torch.Tensor:\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(pil_open),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(RESIZE_SIZE),\n",
    "        transforms.Normalize(IMAGENET_RGB_MEAN, IMAGENET_RGB_STD),\n",
    "    ])(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_damage_target(damage_resolution, *args):\n",
    "    return int(damage_resolution != DamageResolution.NO_DEFECT.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_target = description.damage_verdict.apply(lambda x: get_damage_target(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_FRACTION = 0.7\n",
    "\n",
    "total_size = damage_target.shape[0]\n",
    "train_size = int(total_size * TRAIN_FRACTION)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    img_dir_path=PUBLIC_DATA_FOLDER_PATH,\n",
    "    target_map=damage_target[:train_size].to_dict(),\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader(\n",
    "    img_dir_path=PUBLIC_DATA_FOLDER_PATH,\n",
    "    target_map=damage_target[train_size:total_size].to_dict(),\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    device, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler=None, \n",
    "    save_best_model=True\n",
    "):\n",
    "    best_test_loss = None\n",
    "    best_state_dict = None\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    test_loss_history = []\n",
    "    test_acc_history = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, \n",
    "            device,\n",
    "            train_loader, \n",
    "            criterion, \n",
    "            optimizer\n",
    "        )\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        test_loss, test_acc = test_epoch(model, device, test_loader, criterion)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_acc_history.append(test_acc)\n",
    "        \n",
    "        if best_test_loss is None or test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(\n",
    "            train_loss_history, \n",
    "            test_loss_history, \n",
    "            train_acc_history, \n",
    "            test_acc_history\n",
    "        )\n",
    "    \n",
    "    if save_best_model:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_loss_history, \n",
    "        'test_loss': test_loss_history,\n",
    "        'train_acc': train_acc_history,\n",
    "        'test_acc': test_acc_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace classifier\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "def BCELoss_class_weighted(weights):\n",
    "    \n",
    "    def loss(pred, target):\n",
    "        pred = torch.clamp(pred, min=1e-7, max=1-1e-7)\n",
    "        bce = -weights[1] * target * torch.log(pred) - (1 - target) * weights[0] * torch.log(1 - pred)\n",
    "        return torch.sum(bce)\n",
    "\n",
    "    return loss\n",
    "\n",
    "criterion = BCELoss_class_weighted(weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_model_params_required_grad(model)\n",
    "\n",
    "resnet_simple_fraud_log = train_model(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    train_loader=train_loader, \n",
    "    test_loader=test_loader, \n",
    "    epochs=3, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'baseline_damage.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: There are only **filename**, **pass_id**, **plan_side** in private data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from utils import get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('baseline_damage.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = get_predictions(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_complex_target(row):\n",
    "    real = int(\n",
    "        row.plan_side != row.fact_side or \n",
    "        row.fraud_verdict != 'ALL_GOOD' or\n",
    "        row.damage_verdict != 'NO_DEFECT'\n",
    "    )\n",
    "    return pd.Series(\n",
    "        data=[row.pass_id, real, row.pred],\n",
    "        index=['pass_id', 'real', 'pred'],\n",
    "    )\n",
    "\n",
    "# All predictions for each vehicle are aggregated into a single value, \n",
    "# and the metric is calculated based on the inspections.\n",
    "test_verdicts = test_predictions.merge(\n",
    "    description, \n",
    "    on=['pass_id', 'plan_side']\n",
    ").apply(make_complex_target, axis=1).groupby('pass_id').max()\n",
    "\n",
    "test_verdicts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = roc_auc_score(test_verdicts.real, test_verdicts.pred)\n",
    "print(f'simple fraud target roc_auc_score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_script = '''\n",
    "import typing as t\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import (\n",
    "    get_predictions, \n",
    "    create_dataloader,\n",
    "    PRIVATE_DATA_FOLDER_PATH, \n",
    "    PRIVATE_DATA_DESCRIPTION_PATH,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGENET_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_RGB_STD = [0.229, 0.224, 0.225]\n",
    "RESIZE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "def pil_open(image_data: bytes) -> Image:\n",
    "    return Image.open(io.BytesIO(image_data))\n",
    "\n",
    "\n",
    "def preprocess(image_data: t.Optional[bytes]) -> torch.Tensor:\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(pil_open),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(RESIZE_SIZE),\n",
    "        transforms.Normalize(IMAGENET_RGB_MEAN, IMAGENET_RGB_STD),\n",
    "    ])(image_data)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = torch.load('baseline_damage.pt', map_location=device)\n",
    "\n",
    "description = pd.read_csv(PRIVATE_DATA_DESCRIPTION_PATH, index_col='filename').sort_index()\n",
    "# there is no real target in private data description\n",
    "dummy_target = {key: 0 for key in description.index}\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    img_dir_path=PRIVATE_DATA_FOLDER_PATH,\n",
    "    target_map=dummy_target,\n",
    "    description=description,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    preprocessor=preprocess,\n",
    "    num_load_workers=0,\n",
    ")\n",
    "\n",
    "solution = get_predictions(model, device, val_loader)\n",
    "solution = solution[['pass_id', 'prediction']].groupby('pass_id').max()\n",
    "solution.to_csv('./predictions.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(solution_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the .zip to submit\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "def make_zip_submission(model_path, solution_script):\n",
    "\n",
    "    with open('run.py', 'w') as f_run:\n",
    "        f_run.write(solution_script)\n",
    "\n",
    "    with open('run.sh', 'w') as f_run_sh:\n",
    "        f_run_sh.write('python run.py')\n",
    "\n",
    "    with open('train.py', 'w') as f_run:\n",
    "        f_run.write('print(\"\\\\n\".join(map(str, range(10))))')\n",
    "\n",
    "    with open('train.sh', 'w') as f_run_sh:\n",
    "        f_run_sh.write('python train.py')\n",
    "\n",
    "    with open('Makefile', 'w') as f_makefile:\n",
    "        f_makefile.write('''prepare:\n",
    "\\techo starting...\n",
    "\\tbash train.sh\n",
    "run:\n",
    "\\tbash run.sh\n",
    "''')\n",
    "\n",
    "    submission_zip = zipfile.ZipFile(\n",
    "        f\"submission-{datetime.datetime.now()}.zip\".replace(':', '-').replace(' ', '-'),\n",
    "        \"w\"\n",
    "    )\n",
    "    submission_zip.write('./Makefile', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('run.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('run.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('train.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('train.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('baseline_damage.pt', compress_type=zipfile.ZIP_DEFLATED)\n",
    "    submission_zip.write('utils.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "    submission_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_zip_submission(model_path='baseline_damage.pt', solution_script=solution_script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
